[strings]
# Mode : train, test, serve
train_data_path = ./data/baidurelation2020/train_triples_demo.json
test_data_path = ./data/baidurelation2020/test_triples_demo.json
dev_data_path = ./data/baidurelation2020/dev_triples_demo.json
rel_file = ./data/baidurelation2020/rel2id.json
tag_file = ./data/tag2id.json
# model evaluate result
output_evaluate_path = ./result/
output_evaluate_file = model_evaluate_result.json

# Pretrain model
# pretrain_model_path = D:/pretrain_model/torch/bert-base-chinese/
# pretrain_model_type = bert-base
pretrain_model_path = D:/Spyder/pretrain_model/transformers_torch_tf/bert-base-chinese/
# pretrain_model_type = bert-base
# pretrain_model_path = /home/nlp/pretrain_model/chinese-roberta-wwm-ext/
pretrain_model_type = bert-base

# gpu ids
visible_gpus = -1
# save para
output_path = ./output/
model_name = model.pt
replace_char = â™ 
[ints]
# model para
max_seq_length = 128
epochs = 50
batch_size = 2
seed = 1234
local_rank = 0
eval_interval = 2
require_improvement = 500
pre_epoch_step_print = 2
min_eval_epoch = 2

[floats]
learning_rate = 1e-5
dropout_prob = 0.2
entity_pair_dropout = 0.1
[bools]
is_test = False
